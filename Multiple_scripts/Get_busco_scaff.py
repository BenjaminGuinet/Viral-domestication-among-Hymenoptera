#!/usr/bin/python
import pandas as pd
import numpy as np
import sys
import argparse
import Bio
from Bio import SeqIO
import re

# Print out a message when the program is initiated.
print('-----------------------------------------------------------------------------------\n')
print('                        Get Fasta sequences of scaffolds with a Busco.\n')
print('-----------------------------------------------------------------------------------\n')

#----------------------------------- PARSE SOME ARGUMENTS ----------------------------------------
parser = argparse.ArgumentParser(description='Allow add taxonomy informationsa blast file')
parser.add_argument("-i", "--species_name_file", help="introduce the txt file with species names")
#parser.add_argument("-b", "--blast_file", help="blast-file")

args = parser.parse_args()

Species_name_file=args.species_name_file
#Blast_file=args.blast_file
num_species = sum(1 for line in open(Species_name_file)) # count number of lines in the file in order to now the number of decimals / by the first number given
list_of_names1=[]
for names in open(Species_name_file,"r"):
	list_of_names1.append(names)

list_of_names2=[]

for names in list_of_names1:
	list_of_names2.append(names.replace("\n", ""))

#The idea is to create a chimeric huge fasta file for each genome species. Each chimeric sequence will be the sum of all scaffolds that had at least one BUSCO sequence into it (which means that this scaffold is likely from eucaryot origin)
#To do so we will get the BUSCO summary table generated by the tblasn analysis, this will give us the scaffold that have at least on BUSCO.
#Because we can aldo find virus loci into the same scaffold as BUSCO, will also have to remove from these scaffolds the putative viral loci.
#To do so we will get the viral summary table generated by the mmseqs2 analysis, this will five us the coordinates of the viral loci into each scaffold.
#We will use these coordinates in order to remove them from the scaffolds of interest.

for names in list_of_names2:
	#First we open BUSCO and VIRAL blast table informations
	#scaff_count_busco=  pd.read_csv("/beegfs/data/bguinet/these/Genomes/"+names+"/run_busco/run_BUSCO_v3/blast_output/tblastn_"+names+"_BUSCO_v3.tsv_strand_H.m8", header=0, sep = "\t")
	scaff_count_busco=pd.read_csv("/beegfs/data/bguinet/these/Genomes/"+names+"/run_busco/run_BUSCO_v3/full_table_"+names+"_BUSCO_v3.tsv", comment="#", header=0,sep="\t")
	scaff_count_busco.columns = ['Busco_id','Status','Contig','Start','End','Score','Length']
	scaff_count_viral=  pd.read_csv("/beegfs/data/bguinet/these/Genomes/"+names+"/run_mmseqs2_V/result_mmseqs2_summary_V.m8", header=0, sep = " ")
	#Get the scaffold length informations
	Table_with_length_info=pd.read_csv("/beegfs/data/bguinet/these/Genomes/"+names+"/run_mmseqs2_V/result_mmseqs2_strand_V.m8",sep="\t")
	Table_with_length_info=Table_with_length_info[["query","qlen"]]
	scaff_count_viral = pd.merge(Table_with_length_info,scaff_count_viral, left_on=['query'],right_on=['seqnames'],how="right")
	scaff_count_viral['Newqstart'] = np.where(scaff_count_viral['strand2'].str.contains('-'), scaff_count_viral['qlen'] - scaff_count_viral['end'], scaff_count_viral['start'])
	scaff_count_viral['Newqend'] = np.where(scaff_count_viral['strand2'].str.contains('-'), scaff_count_viral['qlen'] - scaff_count_viral['start'], scaff_count_viral['end'])
	#We create a Chimera_Busco_scaff.fa file to store and concatenate all the scaffolds without the viral loci.
	Chimera_Busco_scaff=open("/beegfs/data/bguinet/these/Genomes/"+names+"/run_busco/Chimera_Busco_scaff.fa","w")
	#Name the unique sequence wich is a concatenate of several scaffolds from eucaryotic origin.
	print(">Chimera_seq",file=Chimera_Busco_scaff)
	#We Open the assembly fasta file of the species to load the scaffolds
	record_dict = SeqIO.to_dict(SeqIO.parse("/beegfs/data/bguinet/these/Genomes/"+names+"/"+names+".fa", "fasta"))
	print("processing for species ", names)
	print("printing into :", "/beegfs/data/bguinet/these/Genomes/"+names+"/run_busco/Chimera_Busco_scaff.fa")
	#Remove duplicates in the busco table because we only need to have the information : in this scaffold there is at least one BUSCO locus.
	scaff_count_busco['Contig'].drop_duplicates(keep='first', inplace=True)
	scaff_count_busco.Contig=scaff_count_busco.Contig.astype(str)
	#Merge the two table
	print(scaff_count_busco)
	print(scaff_count_viral)
	scaff_count_busco_viral = pd.merge(scaff_count_busco,scaff_count_viral, left_on=['Contig'],right_on=['seqnames'],how="outer")
	#Realsea memory 
	scaff_count_viral=pd.DataFrame()
	scaff_count_busco=pd.DataFrame()
	#We will now remove the scaffol where a virus sequence have been located
	scaff_count_busco_viral=scaff_count_busco_viral[scaff_count_busco_viral.Contig != 'nan']
	scaff_count_busco_viral= scaff_count_busco_viral[scaff_count_busco_viral['Start'].notna()]
	#Remove duplicates because the merging made several row that are useless in the process, we only need the number of viral loci into each scaffold.
	#scaff_count_busco_viral=scaff_count_busco_viral.drop_duplicates(subset=['qstart', 'qend'])
	#Create a liste for BUSCO scaffold name that have at least one viral sequence into it
	#Remove scaffold that do not contain a BUSCO
	list_scaff_to_analyse=[]
	for scaffold in scaff_count_busco_viral['Contig']:
		list_scaff_to_analyse.append(scaffold)
	#Remove duplicated scaffold name
	list_scaff_to_analyse=list(dict.fromkeys(list_scaff_to_analyse))
	#Remove nan values 
	list_scaff_to_analyse = [x for x in list_scaff_to_analyse if str(x) != 'nan']
	#For each scaffold containing >=1 BUSCO locus and >=1 viral locus we will remove the viral locus part and print the scaffold into the chimera file.
	count_row = len(list_scaff_to_analyse)
	filecount = 1
	output_sequence=''
	for scaffold in list_scaff_to_analyse:
		#print(scaffold, "in analysing")
		#Focus on the scaffold
		Sub_viral_scaffold_tab=scaff_count_busco_viral.loc[scaff_count_busco_viral['Contig']==scaffold]
		Sub_viral_scaffold_tab=Sub_viral_scaffold_tab.drop_duplicates(['start','end'],keep= 'last')
		#Create a list that will contain all the start and end coordinates of the viral loci
		indexes_to_delete=[]
		#If there is not viral sequence, then the all scaffold is taken 
		if Sub_viral_scaffold_tab.seqnames.isna().all() == True:
			output_sequence = record_dict[scaffold].seq
		#If there are one ore more viral sequence, we will then remove them before taking the scaffold
		else:
			for index, row in Sub_viral_scaffold_tab.iterrows():
				sub_list=list()
				sub_list.append(int(row['Newqstart']))
				sub_list.append(int(row['Newqend']))
				sub_list=tuple(sub_list)
				indexes_to_delete.append(sub_list)
			output_sequence = ''.join(ch for i, ch in enumerate(record_dict[scaffold].seq, 1) if not any(a <= i <= b for a, b in indexes_to_delete))
		#Load the sequence in record_dict
		record_scaff=output_sequence.upper()
		#Remove the nucleotide as "N"
		record_scaff=re.sub('N','',str(record_scaff))
		#Print the scaffold without the viral loci into the chimera busco scaff file
		print(record_scaff,file=Chimera_Busco_scaff)
		filled_len = int(round(50 * filecount / float(count_row -1)))
		percents = round(100.0 * filecount / float(count_row ), 1)
		bar = '=' * filled_len + '-' * ((50) - filled_len)
		sys.stdout.write('[%s] %s%s Get Fasta sequences of scaffolds with a Busco...%s\r' % (bar, percents, '%', ''))
		sys.stdout.flush()  # As suggested by Roid', right_index=True)
		print(filecount,"/",float(count_row -1))
		filecount += 1
	print("recovery done for :", names)


"""
start_value = 0
	#For each sublist in indexes_to_delete, we will remove from the scaffold the viral loci

for start_delete, end_delete in indexes_to_delete:
	output_sequence += record_dict[scaffold].seq[start_value : start_delete]
		#print(output_sequence)
	start_value = end_delete
		#print(start_value)
			#The output_sequence is the scaffold sequence without the viral loci.
	output_sequence += record_dict[scaffold].seq[start_value:]

"""

